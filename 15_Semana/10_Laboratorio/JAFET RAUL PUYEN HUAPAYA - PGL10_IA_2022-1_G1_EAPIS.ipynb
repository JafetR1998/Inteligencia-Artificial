{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Guiada de Laboratorio 10 - Inteligencia Artificial G1 (EAPIS) 2022-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de técnicas de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prof. Rolando A. Maguiña Pérez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la presente práctica, a realizarse el 15 de Agosto del 2022, se abordará el problema denominado “Predicción de cáncer de mama” mediante un par de técnicas  del área de la IA denominada  `Machine Learning`. Luego de la presentación del problema, se entrenarán sus respectivos algoritmos para \"aprender a clasificar\" si los datos corresponden a un cáncer de mama o no; luego, se evaluarán dichos algoritmos sobre un conjunto de datos de validación, y se elegirá el que ofrezca mejores métricas de precisión para elaborar nuestro modelo predictivo. \n",
    "\n",
    "En esa actividades se usará la biblioteca [scikit-learn](https://scikit-learn.org/stable/).\n",
    "\n",
    "Las principales actividades a desarrollar en esta práctica son:\n",
    "* Instalación de la biblioteca llamada scikit-learn y su aplicación para corroborar la construcción correcta de los ratios de acuerdo.\n",
    "* Construcción de un par de algoritmos del área de la IA denominada  `Machine Learning`.\n",
    "* Entrenamiento de las técnicas \n",
    "* Validación del modelo.\n",
    "* Selección de la técnica.\n",
    "\n",
    "Luego de realizar estas actividades  se plantearán algunas preguntas que los alumnos deberán resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetivos de esta Práctica son:\n",
    "- Conocer la herramienta llamada `scikit-learn`.\n",
    "- Conocer la implementación de un par de técnicas de Machine Learning en el `scikit-learn`.\n",
    "- Aprender las etapas del procesamiento de una data: entrenamiento/validación.\n",
    "- Obtener el mejor modelo que resuelva el problema planteado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scikit-learn](https://scikit-learn.org/stable/) es una de las herramientas computacionales más populares y usadas en Machine Learning. Incluye algoritmos para abordar problemas de clasificación, regresión y clustering; asimismo, para otras tareas relacionadas, tales como, reducción de dimensionalidad, preprocesamiento del dataset, entre otras. \n",
    "\n",
    "Para esta PGL se deberá instalar previamente, para luego ser usada en la resolución de un ejercicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación del scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar el scikit-learn siguiendo lo indicado en [Installing the latest release](https://scikit-learn.org/stable/install.html#install-official-release).\n",
    "\n",
    "Se puede usar el sistema de gestión de paquetes llamado `pip` o el `conda`. Se recomienda usar el segundo de los nombrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de cáncer de mama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cáncer es una de las principales causas de mortalidad en todo el mundo y la investigación en su diagnóstico y tratamiento se ha convertido en un tema de vital importancia para la comunidad científica. La prevención sigue siendo un reto, y la mejor manera de aumentar la supervivencia de los pacientes es a través de la detección temprana.\n",
    "\n",
    "Si las células cancerosas son detectadas antes de su diseminación a otros órganos, la tasa de supervivencia es superior al 97%. Por esta razón, el uso y perfeccionamiento de clasificadores automáticos que den soporte al diagnóstico médico se ha incrementado notablemente en los últimos tiempos. Estos sistemas de clasificación tratan de minimizar los posibles errores producidos por los especialistas, aumentar el número de diagnosis que pueden realizar en un tiempo dado, y su porcentaje de éxito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planteamiento del problema ejm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trata del problema de la predicción de cáncer de mama, o breast cancer, un problema bastante conocido en esta área. Consiste en que el sistema computacional \"aprenda a clasificar\" si los datos corresponden a un cáncer benigno o maligno; le debemos enseñar a efectuar esa tarea. Para ello, usaremos un dataset con ejms de personas que han tenido esa enfermedad (ejms positivos) y ejms de personas que no la han tenido  (ejmms negativos). El sistema estará basado en una técnica inteligente, una correspondiente al área de la IA llamada Machine Learning.\n",
    "\n",
    "La base de datos del cáncer de mama de Wisconsin (WBCD) se tomará para la clasificación  de cáncer de mama. La WBCD consta de 699 muestras. Cada registro de la base de datos tiene nueve atributos. Los atributos son numéricos, y es preciso hacer cambios de escala o de unidades, y permite su aproximación como problema de clasificación.\n",
    "\n",
    "Consta de 9 o atributos entradas basadas en características de las células:\n",
    "\n",
    "1. Espesor Macizo\n",
    "2. Uniformidad de tamaño de celula\n",
    "3. La uniformidad de la forma de la célula\n",
    "4. Adherencia Marginal \n",
    "5. Solo tamaño de células epiteliales\n",
    "6. Núcleos desnudos\n",
    "7. Bland Chromatin\n",
    "8. Nucleolos normal\n",
    "9. Mitosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución del problema ejm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pasos que vamos a dar para resolver este problema son los siguientes:  \n",
    "1.\tCarga de los datos y módulos/bibliotecas necesarias para este ejemplo.\n",
    "2.\tExploración de los datos.\n",
    "3.\tEntrenamiento de los dos algoritmos seleccionados.\n",
    "4.\tAplicación del modelo para hacer predicciones a partir de lo «aprendido» y evaluación para seleccionar el modelo más adecuado a este caso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los módulos/bibliotecas y la data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una gran variedad de bibliotecas (librerías) que tenemos disponibles y en cada una de ellas, a su vez, hay módulos distintos.  Pero para poder utilizar, tanto las librerías como los módulos,  hay que importarlos explícitamente (salvo la librería estándar). Para el problema ejemplo importaremos unos módulos que necesitamos para este experimento en particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se carga las librerías a usar. A continuación, se cargará la data. Se hará directamente desde el *sklearn*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'C:\\\\Users\\\\rolan\\\\miniconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_breast_cancer()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es recomendable verificar la información contenida en el dataset. Para ello ejecutamos los sgtes comandos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información en el dataset:\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Información en el dataset:\")\n",
    "print(dataset.keys())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos las características del dataset. Usamos la clave `DESCR`, la cual proporciona una explicación de la estructura del conjunto de datos. Para leerlo, use la función print():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características del dataset:\n",
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(\"Características del dataset:\")\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos todas las columnas. Asimismo, definimos los datos correspondientes a las etiquetas (variable de salida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de la técnica (algoritmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta subsección se van a crear un par de modelos a partir de los datos conocidos y estimar su precisión sobre datos nuevos. Para ello vamos a realizar los siguientes pasos:\n",
    "- Crear un dataset de validación con una parte de los datos disponibles.\n",
    "- Construir 2 modelos diferentes para predecir, a partir de los datos de entrada recogidos en el dataset, si se trata de un cáncer de mama o no.\n",
    "- Seleccionar el mejor de los dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación del conjunto de datos de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que debemos entrenar las técnicas de modo que aprendan a clasificar si los datos de entrada corresponden a un cáncer de mama o no. Ello permitirá obtener los modelos respectivos. Allí surgirá una pregunta: ¿Cómo saber si nuestro modelo es bueno?. Para resolver esto vamos a usar las métricas vistas en una sesión anterior, relacionadas a la Matriz de Confusión.  Dichas métricas permiten evaluar la «calidad» de un modelo basado en Machine Learning. \n",
    "\n",
    "Con esa finalidad se separa la data en un conjunto de datos para el entrenamiento y en un segundo conjunto con datos para la validación, es decir, para probar los modelos; para ello, reservaremos un 20% de los datos del dataset original. Así, aplicándolo a este conjunto de validación, podremos comprobar cómo funciona el modelo, aquel que generamos entrenando el respectivo algoritmo con el 80% restante.\n",
    "\n",
    "Para tal efecto, se importan desde *sklearn* los módulos necesarios. Asimismo, se escalarán todos los datos de modo que no haya diferencia en el orden de magnitud en las atributos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# Se escalan todos los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "escalar = StandardScaler()\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a priori no sabemos qué técnicas (algoritmos) pueden funcionar mejor para este problema, vamos a probar con 2 diferentes, ambos no lineales. Las gráficas iniciales ya indican que podemos ir por buen camino, porque se aprecia que algunas clase. Vamos a evaluar los siguientes algoritmos:\n",
    "\n",
    "*\tRegresión logística (LR)\n",
    "*\tK-Vecinos más cercanos (K-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la primera técnica a utilizar, en este caso la denominada Regresión Logística. Desde el *sklearn* importaremos los módulos que se requieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "algoritmo = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez implementada la técnica en el entorno del *sklearn*, se entrena el modelo con el algoritmo respectivo usando la data de entrenamiento (X_train, y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoritmo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación del modelo para hacer predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha llegado el momento de poner a prueba el modelo creado a partir de los datos de entrenamiento. Con esa finalidad, debemos aplicarlo a esa parte del dataset original que separamos al principio como dataset de validación. Como se dispone de los valores correctos de clasificación, y no se han usado en el entrenamiento del modelo (tampoco se usaron los datos sobre los atributos de entrada), si comparamos los valores reales con los predichos por el modelo sabremos si el modelo está funcionando correctamente o  no; incluso se podrá cuantificar en qué medida lo está haciendo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se realiza la predicción y se verifica, usando la matriz de confusión, el comportamiento del modelo mediante las métricas *exactitud* y *precisión* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[39  4]\n",
      " [ 1 70]]\n",
      "Precisión del modelo:\n",
      "0.9459459459459459\n",
      "Exactitud del modelo:\n",
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "y_pred = algoritmo.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(matriz)\n",
    "# Precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precisión del modelo:\")\n",
    "print(precision)\n",
    "# Exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementaremos mediante las funciones necesarias la técnica llama K- Vecinos más cercanos. Enseguida, análogamente a lo realizado para la Regresión Logística, se entrenará el modelo y se verificará usando otra vez la matriz de confusión y la métrica *precisión* el desempeño del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "algoritmo = KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2)\n",
    "# Entreno el modelo\n",
    "algoritmo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación del modelo para hacer predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se realiza la predicción y la verificación del desempeño:\n",
    "Para aplicar el  modelo basado en el algoritmo SVM, no tenemos más que ejecutar el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[38  5]\n",
      " [ 2 69]]\n",
      "Precisión del modelo:\n",
      "0.9324324324324325\n"
     ]
    }
   ],
   "source": [
    "y_pred = algoritmo.predict(X_test)\n",
    "# Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(matriz)\n",
    "# Precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precisión del modelo:\")\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elección del mejor modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar la celda, se observan los estimadores para cada modelo. De esta forma, es posible compararlos y elegir el modelo que funciona mejor. A partir de  los resultados obtenidos, observamos que el modelo que da un mayor valor de exactitud es la Regresión Logística (94%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hemos basado el modelo en las técnicas llamadas Regresión Logística y K-NN SVM, obteniéndose   buenos resultados tanto en exactitud como en precisión para la primera;  los valores de precisión para K-NN, según se pudo observar, también son buenos. Aplique ahora las  técnicas denominadas SVM y Árboles de Decisión y compáre los resultados obtenidos con los obtenidos con las dos primeras técnicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aplique los ratios denominados Accuracy (Exactitud), Precision (Precisión), Sensibilidad (Recall) y F-measure (F1), que implementó en una Práctica anterior mediante funciones de Python, al problema. Analice sus resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrucciones para el envío de la solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución de la \"Práctica Guiada de Laboratorio 10 - IA 2022-1 G1 EPIS\" podrá enviarse como respuesta a la tarea del mismo nombre publicada en la clase de Classroom, hasta las 23:59 h del Viernes 19 de Agosto del 2022, en un archivo con extensión .ipynb.\n",
    "\n",
    "El documento deberá tener las sgtes características:\n",
    "\n",
    "Nombre del archivo: solPGL10_IA_G1_nombre-apellidos.ipynb.\n",
    "\n",
    "Todas las preguntas de la Práctica deben responderse en este mismo cuaderno computacional; la solución a cada pregunta debe registrarse en una celda debajo del planteamiento de la misma, mencionando explícitamente como subtítulo: \"Solución del ejercicio n\", donde \"n\" corresponde al número del ejercicio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
